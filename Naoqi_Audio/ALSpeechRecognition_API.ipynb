{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALSpeechRecognition API\n",
    "___\n",
    "> #include <alproxies/alspeechrecognitionproxy.h>\n",
    "\n",
    "## Method list \n",
    "___\n",
    ": 여타 module과 같이, 이 모듈은 ALModule API로 부터 method를 상속받습니다. 또한 다음과 같은 구체적인 방법이 있습니다.\n",
    "\n",
    "#### class ALSpeechRecognitionProxy\n",
    "1. ALSpeechRecognitionProxy::getAvailableLanguages\n",
    "2. ALSpeechRecognitionProxy::getLanguage\n",
    "3. ALSpeechRecognitionProxy::setLanguage\n",
    "4. ALSpeechRecognitionProxy::getParameter\n",
    "5. ALSpeechRecognitionProxy::setParameter\n",
    "6. ALSpeechRecognitionProxy::loadVocabulary (deprecated)\n",
    "7. ALSpeechRecognitionProxy::getAudioExpression\n",
    "8. ALSpeechRecognitionProxy::setAudioExpression\n",
    "9. ALSpeechRecognitionProxy::setVisualExpression\n",
    "10. ALSpeechRecognitionProxy::setVocabulary\n",
    "11. ALSpeechRecognitionProxy::setWordListAsVocabulary (deprecated)\n",
    "12. ALSpeechRecognitionProxy::compile\n",
    "13. ALSpeechRecognitionProxy::addContext\n",
    "14. ALSpeechRecognitionProxy::removeContext\n",
    "15. ALSpeechRecognitionProxy::removeAllContext\n",
    "16. ALSpeechRecognitionProxy::saveContextSet\n",
    "17. ALSpeechRecognitionProxy::loadContextSet\n",
    "18. ALSpeechRecognitionProxy::eraseContextSet\n",
    "19. ALSpeechRecognitionProxy::activateRule\n",
    "20. ALSpeechRecognitionProxy::deactivateRule\n",
    "21. ALSpeechRecognitionProxy::activateAllRules\n",
    "22. ALSpeechRecognitionProxy::deactivateAllRules\n",
    "23. ALSpeechRecognitionProxy::addWordListToSlot\n",
    "24. ALSpeechRecognitionProxy::removeWordListFromSlot\n",
    "25. ALSpeechRecognitionProxy::getRules\n",
    "26. ALSpeechRecognitionProxy::pause\n",
    "27. ALSpeechRecognitionProxy::subscribe\n",
    "28. ALSpeechRecognitionProxy::unsubscribe\n",
    "\n",
    "## Event List\n",
    "__\n",
    "1. WordRecognized()\n",
    "2. WordRecognizedAndGrammar()\n",
    "3. LastWordRecognized() (deprecated)\n",
    "4. SpeechDetected()\n",
    "5. ALSpeechRecognition/ActiveListening()\n",
    "6. ALSpeechRecognition/IsRunning()\n",
    "7. ALSpeechRecognition/Status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "___\n",
    "\n",
    "###  std::vector<<std::string>>ALSpeechRecognitionProxy::getAvailableLanguages()\n",
    "\n",
    ": 현재 시스템에 설치된 언어 목록을 반환한다.\n",
    "\n",
    "    Returns: 언어의 list\n",
    "            Example: [‘French’, ‘Chinese’, ‘English’, ‘Japanese’]\n",
    "\n",
    "___\n",
    "\n",
    "### std::string ALSpeechRecognitionProxy::getLanguage()\n",
    "\n",
    ": 현재 speech recognition 시스템에 사용된 언어를 반환한다.\n",
    "\n",
    "    Returns: 언어의 이름.\n",
    "            Example: ‘French’\n",
    "\n",
    "            설치된 언어들 중 하나가 될 수 있다 :\n",
    "            ALSpeechRecognitionProxy::getAvailableLanguages\n",
    "            \n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::setLanguage(const std::string& language)\n",
    "\n",
    ": 현재 speech recognition system application에서 사용할 언어를 설정한다.\n",
    "\n",
    "> Warning : 다른 ALSpeechRecognition 혹은 ALDialog method와 동시에 불러질 수 없다.\n",
    "\n",
    ": 설정 값은 application이 끝나면 기본 설절 언어로 돌아간다.\n",
    "\n",
    "더 자세한 정보를 알고 싶다면, see : pepp Setting Pepper’s preferred language. (http://doc.aldebaran.com/2-5/family/pepper_user_guide/setting_language_pep.html#setting-usual-language-pep)\n",
    "\n",
    "    Parameters:\tlanguage –\n",
    "                사용가능한 언어들중 하나의 이름.\n",
    "\n",
    "                Example: ‘French’\n",
    "\n",
    "                See: ALSpeechRecognitionProxy::getAvailableLanguages.\n",
    "\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::getParameter(const std::string& parameter)\n",
    "\n",
    ": speech recognition engine의 파라미터를 가져온다.\n",
    "\n",
    "    Parameters:\tparameter – parameter의 이름\n",
    "    \n",
    "    Returns: parameter의 값\n",
    "    \n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::setParameter(const std::string& parameter, const float& value)\n",
    "\n",
    ": speech recognition engine의 파라미터들을 설정한다.\n",
    "\n",
    "    Parameters:\tparameter – parameter의 이름\n",
    "                value – parameter의 값\n",
    "    \n",
    "    Supported parameters : \n",
    "        1. Sensitivity: 0과 1사이의 값으로, engine에서 사용하는 음성 활성 감지기의 감도를 설정한다.\n",
    "        2. NbHypotheses: engine에 의해 return된 추측들의 수 / Default: 1\n",
    "        \n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::loadVocabulary(const std::string& pathToGrammarfile)\n",
    "\n",
    ": 1.20버전 이후로 삭제됨  - ALSpeechRecognitionProxy::setVocabulary 를 대신 사용하라.\n",
    "\n",
    ": recognize하기 위해 .lcf or .fcf 파일에(NUANCE grammar file format) 포함된 단어를 로드한다.\n",
    "    \n",
    "    Parameters:\tpathToGrammarfile – 단어를 포함하고 있는 .lcf or .fcf 파일로의 경로\n",
    "    \n",
    "___\n",
    "\n",
    "### bool ALSpeechRecognitionProxy::getAudioExpression()\n",
    "\n",
    ": AudioExpression 파라미터의 값을 가져온다. 이 파라미터는 recognition process가 'bip'을 재생하는지의 여부를 포함한다. \n",
    "\n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::setAudioExpression(const bool& setOrNot)\n",
    "\n",
    ": 'True'로 세팅되어 있으면, 'bip'이 recognition process의 시작에 재생되고, 또 다른 'bip'은 process의 마지막에 재생된다. 이것은 사용자가 말할 적절한 때를 알 수 있게 돕는 유용한 표현이다. \n",
    "\n",
    "    Parameters:\tsetOrNot – Enable (true) or disable it (false).\n",
    "    \n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::setVisualExpression(const bool& setOrNot)\n",
    "\n",
    ":  recognition process 중에 recognition engine의 상태를 표시하는 LED 애니메이션을 활성화하거나 비활성화한다.\n",
    "\n",
    "\n",
    "    Parameters:\tsetOrNot – Enable (true) or disable it (false).\n",
    "    \n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::setVocabulary(const std::vector<std::string>& vocabulary, const bool& enableWordSpotting)\n",
    "\n",
    ": speech recognition engine에서 인식해야하는 단어들/구절들의 list를 설정한다. \n",
    "\n",
    "만약 word spotting이 비활성화된다면(default), engine은 지정된 단어들 중 더이상 혹은 그이하도 아닌 하나만을 예측한다. \n",
    "\n",
    "만약 활성화된다면, 지정된 단어들은 전체 speech stream(list)의 가운데에서 발음할 수 있다 : engine이 이를 감지하려고 시도한다. \n",
    "\n",
    "파라미터인 enableWordSpotting은 speech recognition에 의해 주어진 결과를 바꾼다. ALSpeechRecognition을 참조하라.\n",
    "\n",
    "    Parameters:\t\n",
    "                vocabulary – recignized 되어야만 하는 단어들의 list\n",
    "                enableWordSpotting – Enable (true) or disable it (false)\n",
    "                \n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::setWordListAsVocabulary(const std::vector<std::string>& vocabulary)\n",
    "Deprecated since version 1.20: use ALSpeechRecognitionProxy::setVocabulary instead.\n",
    "\n",
    ": 1.2 버전 이후로 삭제됨. ALSpeechRecognitionProxy::setVocabulary 를 대신 사용하라.\n",
    "\n",
    "speech recognition engine에 의해 인식해야만 하는 단어들/구절들의 list를 설정한다. \"word spotting\"을 활성화하려면, ALSpeechRecognitionProxy::setVocabulary를 대신 사용하라.\n",
    "\n",
    "    Parameters:\tvocabulary – recignized 되어야만 하는 단어들의 list\n",
    "\n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::compile(const std::string& pathToInputBNFFile, const std::string& pathToOutputLCFFile, const std::string& language)\n",
    "\n",
    ": BNF 파일을 LCF 파일로 변환한다. LCF 파일은 BNF 파일과 같은 내용을 포함하는 2진파일이다. addContext method에 이 파일을 사용하라.\n",
    "\n",
    "    Parameters: pathToInputBNFFile – BNF 입력 파일의 경로이다. BNF 파일은 speech recognition engine에 의해 인식되어야하는 일련의 규칙이다.\n",
    "                pathToOutputLCFFile – LCF 파일이 생성되어질 경로.\n",
    "               language – BNF 파일의 언어 이름\n",
    "              \n",
    "\n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::addContext(const std::string& pathToLCFFile, const std::string& contextName)\n",
    "\n",
    ": LCF 파일 안에 포함된 context를 추가해라. 이 LCF 파일은 speech recognition engine에 의해 recognized 되야하는 일련의 규칙을 포함한다.\n",
    "\n",
    "    Parameters:\t\n",
    "                pathToLCFFile – 사용할 LCF file의 경로.\n",
    "                contextName – context의 이름.\n",
    "                \n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::removeContext(const std::string& contextName)\n",
    "\n",
    ": speech recognition engine으로부터 하나의 context를 제거한다.\n",
    "\n",
    "    Parameters:\t\n",
    "                contextName – 제거할 context의 이름.\n",
    "\n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::removeAllContext()\n",
    "\n",
    ": speech recognition engine으로부터 모든 context를 제거한다.\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::saveContextSet(const std::string& saveName)\n",
    "\n",
    ": 설정한 saveName의 이름하에 현재 context set를 저장한다.\n",
    "\n",
    "=> 저장된 context set들은 NaoQi 를 재시작할때 사라진다.\n",
    "\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::loadContextSet(const std::string& saveName)\n",
    "\n",
    ": saveName이라는 이름하에 이전에 저장했던 context set에 의해 현재 load 된 context set를 대체한다.\n",
    "\n",
    "Note: 저장된 context를 Reloading 하는 것을 그 상태를 reset하진 않는다; 즉, 마지막으로 저장한 이후 활성된 규칙들, 슬롯들에 변경된 내용은 지워지지 않는다. \n",
    "\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::eraseContextSet(const std::string& saveName)\n",
    "\n",
    ": 저장 saveName 지우기. 이것은 현재 로드된 context들을 제거하진 않을 것이다.\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::activateRule(const std::string& contextName, const std::string& ruleName)\n",
    "\n",
    ": 특정 context 안에 포함된 규칙을 활성화 한다.\n",
    "\n",
    "    Parameters:\t\n",
    "                contextName – 수정할 context의 이름.\n",
    "                ruleName – 활성화 할 규칙의 이름.\n",
    "\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::deactivateRule(const std::string& contextName, const std::string& ruleName)\n",
    "\n",
    ": 특정 context 안에 포함된 규칙을 비활성화 한다.\n",
    "\n",
    "    Parameters:\t\n",
    "                contextName – 수정할 context의 이름.\n",
    "                ruleName – 활성화 할 규칙의 이름.\n",
    "\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::activateAllRules(const std::string& contextName)\n",
    "\n",
    ": 특정 context 안에 포함된 모든 규칙을 활성화 한다.\n",
    "\n",
    "    Parameters:\t\n",
    "                contextName – 수정할 context의 이름.\n",
    "\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::deactivateAllRules(const std::string& contextName)\n",
    "\n",
    "\n",
    ": 특정 context 안에 포함된 모든 규칙을 비활성화 한다.\n",
    "\n",
    "    Parameters:\t\n",
    "                contextName – 수정할 context의 이름.\n",
    "\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::addWordListToSlot(const std::string& contextName, const std::string& slotName, const std::vector<std::string>& wordList)\n",
    "\n",
    ": slot에 단어들의 list를 추가한다. slot은 수정가능한 context의 한 부분이다. 당신은 speech recognition engine에 의해 recognized되어야만 하는 단어들의 list를 추가 할 수 있다.\n",
    "\n",
    "    Parameters:\t\n",
    "                contextName – 수정할 context의 이름.\n",
    "                slotName – 수정할 slot의 이름.\n",
    "                wordList – slot 안에 넣어줄 단어들의 list.\n",
    "\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::removeWordListFromSlot(const std::string& contextName, const std::string& slotName)\n",
    "\n",
    ": slot으로부터 모든 단어들을 제거한다.\n",
    "\n",
    "\n",
    "    Parameters:\t\n",
    "                contextName – 수정할 context의 이름.\n",
    "                slotName – 수정할 slot의 이름.\n",
    "\n",
    "___\n",
    "\n",
    "### std::vector<<std::string>> ALSpeechRecognitionProxy::getRules(const std::string& contextName, const std::string& typeName)\n",
    "\n",
    ": 특정 type에 해당하는 rule들을 가져온다. type들은 아래와 같다 :\n",
    "\n",
    "1. “start”: context안에 진입점(entry point)을 제공한다.\n",
    "2. “active”: rule의 상태, 즉 rule 이 활성화 했는지 혹은 아닌지의 여부를 나타낸다.\n",
    "3. “activatable”: 활성화 또는 비활성화할 수 있는 rule 을 지정한다.\n",
    "4. “slot”: 이러한 rule 들은 runtime동안 바뀔 수 있다.\n",
    "\n",
    "    Parameters:\t\n",
    "                contextName – context의 이름.\n",
    "                typeName – 지시된 rule들의 타입.\n",
    "\n",
    "___\n",
    "\n",
    "### float ALSpeechRecognitionProxy::pause(const bool& isPaused)\n",
    "\n",
    ": input parameter에 따라 speech recognition engine이 멈추거나 재시작 한다.\n",
    "\n",
    "예를 들면, 이것은 context들을 추가 할때, context의 rule들을 활성화하고 비활성화할때 그리고 slot에 단어들을 추가할때 사용된다.\n",
    "\n",
    "    Parameters:\t\n",
    "                isPaused – True (stops ASR) or False (restarts ASR).\n",
    "\n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::subscribe(const std::string& name)\n",
    "\n",
    ": ALSpeechRecognition 을 구독한다. 이는 모듈로 하여금 \"WordRecognized\"안의 ALMemory에 정보를 작성하기 시작하게 한다. 이는 ALMemoryProxy::getData를 사용하여 ALMemory로 접근할 수 있다.\n",
    "\n",
    "    Parameters:\t\n",
    "                name – subscriber를 구별할 수 있는 이름.\n",
    "___\n",
    "\n",
    "### void ALSpeechRecognitionProxy::unsubscribe(const std::string& name)\n",
    "\n",
    ": ALSpeechRecognition 구독을 취소한다. 이는 모듈로 하여금 \"WordRecognized\"안의 ALMemory에 정보를 작성하는 것을 멈추게 한다.\n",
    "\n",
    "    Parameters:\t\n",
    "                name – subscriber를 구별할 수 있는 이름 (ALSpeechRecognitionProxy::subscribe 에 사용되는 것처럼.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events\n",
    "___\n",
    "\n",
    "### Event: \"WordRecognized\"\n",
    ">\n",
    ">callback(std::string eventName, AL::ALValue value, std::string subscriberIdentifier)\n",
    "\n",
    ":  ALSpeechRecognitionProxy::setVocabulary로 지정된 words set 중 하나가 recognized되었을때 발생한다. 현재 인식된 단어가 없을때, 이 값은 다시 초기화 된다.\n",
    "\n",
    "    Parameters:\t\n",
    "                eventName (std::string) – “WordRecognized”\n",
    "                value – Recognized된 단어들의 정보. 자세한 내용은 ALSpeechRecognition를 참조하라.\n",
    "                subscriberIdentifier (std::string) –\n",
    "\n",
    "___\n",
    "\n",
    "### Event: \"WordRecognizedAndGrammar\"\n",
    ">\n",
    "> callback(std::string eventName, AL::ALValue value, std::string subscriberIdentifier)\n",
    "\n",
    ": engine이 결과를 생산할때 발생한다. WordRecognized와 같은 추가 정보로 인식되며, recognition에 사용되는 문법의 이름이다.\n",
    "\n",
    "    Parameters:\t\n",
    "                eventName (std::string) – “WordRecognizedAndGrammar”\n",
    "                value – Recognized된 단어들의 정보. 자세한 내용은 ALSpeechRecognition을 참조하라.\n",
    "                subscriberIdentifier (std::string) –\n",
    "\n",
    "___\n",
    "\n",
    "### Event: \"LastWordRecognized\"\n",
    ">\n",
    "> callback(std::string eventName, AL::ALValue value, std::string subscriberIdentifier)\n",
    "\n",
    ": 1.20버전 이후로 삭제 됨.\n",
    "\n",
    ": ALSpeechRecognitionProxy::setWordListAsVocabulary로 지정된 단어들 중 하나가 recognized된 경우 발생한다. 이 값은 새로운 단어가 인식될때까지 변경되지 않는다.\n",
    "\n",
    "    Parameters:\t\n",
    "                eventName (std::string) – “LastWordRecognized”\n",
    "                value – 마지막으로 인식된 단어들의 정보들. 자세한 내용은 ALSpeechRecognition을 참조하라.\n",
    "                subscriberIdentifier (std::string) –\n",
    "\n",
    "___\n",
    "\n",
    "### Event: \"SpeechDetected\"\n",
    ">\n",
    "> callback(std::string eventName, bool value, std::string subscriberIdentifier)\n",
    "\n",
    ": 자동 speech recognition engine이 음성 활동을 감지한 경우 발생된다.\n",
    "\n",
    "    Parameters:\t\n",
    "                eventName (std::string) – “SpeechDetected”\n",
    "                value – 음성 활동이 감지될 경우 True.\n",
    "                subscriberIdentifier (std::string) –\n",
    "\n",
    "___\n",
    "\n",
    "### Event: \"ALSpeechRecognition/IsRunning\"\n",
    ">\n",
    "> callback(std::string eventName, bool value, std::string subscriberIdentifier)\n",
    "\n",
    ": speech recognition engine이 시작되면 발생한다.\n",
    "\n",
    "    Parameters:\t\n",
    "                eventName (std::string) – “ALSpeechRecognition/IsRunning”\n",
    "                value – speech recognition engine이 시작되면 True.\n",
    "                subscriberIdentifier (std::string) –\n",
    "\n",
    "___\n",
    "\n",
    "### Event: \"ALSpeechRecognition/Status\"\n",
    ">\n",
    "> callback(std::string eventName, AL::ALValue status, std::string subscriberIdentifier)\n",
    "\n",
    ": speech recognition engine의 상태가 변경될 경우 발생한다.\n",
    "\n",
    "    Parameters:\t\n",
    "                eventName (std::string) – “ALSpeechRecognition/Status”\n",
    "                status –\n",
    "                “Idle”, “ListenOn”, “SpeechDetected”, “EndOfProcess”, “ListenOff”, “Stop” 이러한 상태가 될 수 있다.\n",
    "\n",
    "                Note: “ListenOn” 상태는 반드시 처리할 준비가 되어 있다는 것을 의미하지 않는다. 자세한 정보를 알고 싶다면, see: ALSpeechRecognition/ActiveListening(). ()\n",
    "\n",
    "                subscriberIdentifier (std::string) –\n",
    "\n",
    "___\n",
    "\n",
    "### Event: \"ALSpeechRecognition/ActiveListening\"\n",
    ">\n",
    "> callback(std::string eventName, bool value, std::string subscriberIdentifier)\n",
    "\n",
    "#### Experimental\n",
    "\n",
    ": engine이 수신 대기 중일 뿐만 아니라 데이터 처리 준비상태 일때, True 값 발생한다. (즉, ASR engine이 처리항 소리만을 녹음할 때는 발생하지 않는다).\n",
    "\n",
    "    Parameters:\t\n",
    "                eventName (std::string) – “ALSpeechRecognition/ActiveListening”\n",
    "                value – engine이 듣고 있고 데이터를 처리하려고 하는 경우 True, 반대인 경우 False.\n",
    "                subscriberIdentifier (std::string) –"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
